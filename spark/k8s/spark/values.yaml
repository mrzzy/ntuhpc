## @section Spark parameters
##

## Bitnami Spark image version
## ref: https://hub.docker.com/r/bitnami/spark/tags/
## @param image.registry [default: REGISTRY_NAME] Spark image registry
## @param image.repository [default: REPOSITORY_NAME/spark] Spark image repository
## @skip image.tag Spark image tag (immutable tags are recommended)
## @param image.digest Spark image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
## @param image.pullPolicy Spark image pull policy
## @param image.pullSecrets Specify docker-registry secret names as an array
## @param image.debug Enable image debug mode
##
image:
  registry: docker.io
  repository: bitnami/spark
  tag: 3.5.2-debian-12-r1
  digest: ""
  ## Specify a imagePullPolicy
  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
  ##
  pullPolicy: IfNotPresent

## @section Spark master parameters
##

## Spark master specific configuration
##
master:
  ## @param master.containerPorts.http Specify the port where the web interface will listen on the master over HTTP
  ## @param master.containerPorts.https Specify the port where the web interface will listen on the master over HTTPS
  ## @param master.containerPorts.cluster Specify the port where the master listens to communicate with workers
  ##
  containerPorts:
    http: 8080
    https: 8480
    cluster: 7077
  ## Container resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param master.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if master.resources is set (master.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "small"
  ## @param master.configOptions Use a string to set the config options for in the form "-Dx=y"
  ##
  configOptions: -Dspark.ui.reverseProxy=true
    -Dspark.ui.reverseProxyUrl=http://spark.ntuhpc.org

## @section Spark worker parameters
##

## Spark worker specific configuration
##
worker:
  ## @param worker.containerPorts.http Specify the port where the web interface will listen on the worker over HTTP
  ## @param worker.containerPorts.https Specify the port where the web interface will listen on the worker over HTTPS
  ## @param worker.containerPorts.cluster Specify the port where the worker listens to communicate with workers
  ##
  containerPorts:
    http: 8080
    https: 8480
    cluster: ""
  ## @param worker.daemonMemoryLimit Set the memory limit for the worker daemon
  ##
  daemonMemoryLimit: ""
  ## @param worker.memoryLimit Set the maximum memory the worker is allowed to use
  ##
  memoryLimit: ""
  ## @param worker.coreLimit Se the maximum number of cores that the worker can use
  ##
  coreLimit: ""
  ## @param worker.dir Set a custom working directory for the application
  ##
  dir: ""
  ## @param worker.javaOptions Set options for the JVM in the form `-Dx=y`
  ##
  javaOptions: ""
  ## @param worker.configOptions Set extra options to configure the worker in the form `-Dx=y`
  ##
  configOptions: -Dspark.ui.reverseProxy=true
    -Dspark.ui.reverseProxyUrl=http://spark.ntuhpc.org
  ## @param worker.extraVolumes Optionally specify extra list of additional volumes for the worker pod(s)
  ##
  extraVolumes:
    - name: spark-events
      persistentVolumeClaim:
        claimName: spark-events
  ## @param worker.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the master container(s)
  ##
  extraVolumeMounts:
    - mountPath: "/tmp/spark-events"
      name: spark-events
  ## @param worker.extraEnvVars An array to add extra env vars
  ## For example:
  ## extraEnvVars:
  ##  - name: SPARK_DAEMON_JAVA_OPTS
  ##    value: -Dx=y
  ##
  extraEnvVars: []
  ## @param worker.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for worker nodes
  ##
  extraEnvVarsCM: ""
  ## @param worker.extraEnvVarsSecret Name of existing Secret containing extra env vars for worker nodes
  ##
  extraEnvVarsSecret: ""
  ## @param worker.replicaCount Number of spark workers (will be the minimum number when autoscaling is enabled)
  ##
  replicaCount: 16
  ## Container resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param worker.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if worker.resources is set (worker.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "2xlarge"
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param worker.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param worker.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param worker.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable. Defaults to `1` if both `worker.pdb.minAvailable` and `worker.pdb.maxUnavailable` are empty.
  ##
  pdb:
    create: true
    minAvailable: ""
    maxUnavailable: "4"
  ## Autoscaling parameters
  ## @param worker.autoscaling.enabled Enable replica autoscaling depending on CPU
  ## @param worker.autoscaling.minReplicas Minimum number of worker replicas
  ## @param worker.autoscaling.maxReplicas Maximum number of worker replicas
  ## @param worker.autoscaling.targetCPU Target CPU utilization percentage
  ## @param worker.autoscaling.targetMemory Target Memory utilization percentage
  ##
  autoscaling:
    enabled: false
    minReplicas: ""
    maxReplicas: 5
    targetCPU: 50
    targetMemory: ""

## @section Traffic Exposure parameters
##

## Service parameters
##
service:
  ## @param service.type Kubernetes Service type
  ##
  type: NodePort
  ## @param service.ports.http Spark client port for HTTP
  ## @param service.ports.https Spark client port for HTTPS
  ## @param service.ports.cluster Spark cluster port
  ##
  ports:
    http: 80
    https: 443
    cluster: 7077
  ## Specify the nodePort(s) value(s) for the LoadBalancer and NodePort service types.
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
  ## @param service.nodePorts.http Kubernetes web node port for HTTP
  ## @param service.nodePorts.https Kubernetes web node port for HTTPS
  ## @param service.nodePorts.cluster Kubernetes cluster node port
  ##
  nodePorts:
    http: "30001"
    https: "30002"
    cluster: "30003"
  ## @param service.clusterIP Spark service Cluster IP
  ## e.g.:
  ## clusterIP: None
  ##
  clusterIP: ""

## Configure the ingress resource that allows you to access the
## Spark installation. Set up the URL
## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
##
ingress:
  ## @param ingress.enabled Enable ingress controller resource
  ##
  enabled: true
  ## @param ingress.pathType Ingress path type
  ##
  pathType: ImplementationSpecific
  ## @param ingress.hostname Default host for the ingress resource
  ##
  hostname: spark.ntuhpc.org
  ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
  ##
  ingressClassName: ""
  ## @param ingress.path The Path to Spark. You may need to set this to '/*' in order to use this with ALB ingress controllers.
  ##
  path: /
  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
  ## For a full list of possible ingress annotations, please see
  ## ref: https://github.com/kubernetes/ingress-nginx/blob/main/docs/user-guide/nginx-configuration/annotations.md
  ## Use this parameter to set the required annotations for cert-manager, see
  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
  ##
  ## e.g:
  ## annotations:
  ##   kubernetes.io/ingress.class: nginx
  ##   cert-manager.io/cluster-issuer: cluster-issuer-name
  ##
  annotations: {}

## Metrics configuration
##
metrics:
  ## @param metrics.enabled Start a side-car prometheus exporter
  ##
  enabled: false
  ## @param metrics.masterAnnotations [object] Annotations for the Prometheus metrics on master nodes
  ##
  masterAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: "/metrics/"
    prometheus.io/port: "{{ .Values.master.containerPorts.http }}"
  ## @param metrics.workerAnnotations [object] Annotations for the Prometheus metrics on worker nodes
  ##
  workerAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/path: "/metrics/"
    prometheus.io/port: "{{ .Values.worker.containerPorts.http }}"
  ## Prometheus Service Monitor
  ## ref: https://github.com/coreos/prometheus-operator
  ##      https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
  ##
  podMonitor:
    ## @param metrics.podMonitor.enabled If the operator is installed in your cluster, set to true to create a PodMonitor Resource for scraping metrics using PrometheusOperator
    ##
    enabled: false
    ## @param metrics.podMonitor.extraMetricsEndpoints Add metrics endpoints for monitoring the jobs running in the worker nodes
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#podmetricsendpoint
    ## e.g:
    ## - port: myapp
    ##   path: /metrics/
    ##
    extraMetricsEndpoints: []
    ## @param metrics.podMonitor.namespace Specify the namespace in which the podMonitor resource will be created
    ##
    namespace: ""
    ## @param metrics.podMonitor.interval Specify the interval at which metrics should be scraped
    ##
    interval: 30s
    ## @param metrics.podMonitor.scrapeTimeout Specify the timeout after which the scrape is ended
    ## e.g:
    ## scrapeTimeout: 30s
    ##
    scrapeTimeout: ""
    ## @param metrics.podMonitor.additionalLabels Additional labels that can be used so PodMonitors will be discovered by Prometheus
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
    ##
    additionalLabels: {}
  ## Custom PrometheusRule to be defined
  ## The value is evaluated as a template, so, for example, the value can depend on .Release or .Chart
  ## ref: https://github.com/coreos/prometheus-operator#customresourcedefinitions
  ##
  prometheusRule:
    ## @param metrics.prometheusRule.enabled Set this to true to create prometheusRules for Prometheus
    ##
    enabled: false
    ## @param metrics.prometheusRule.namespace Namespace where the prometheusRules resource should be created
    ##
    namespace: ""
    ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so prometheusRules will be discovered by Prometheus
    ##
    additionalLabels: {}
    ## @param metrics.prometheusRule.rules Custom Prometheus [rules](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/)
    ## These are just examples rules, please adapt them to your needs.
    ## Make sure to constraint the rules to the current postgresql service.
    ## rules:
    ##   - alert: HugeReplicationLag
    ##     expr: pg_replication_lag{service="{{ template "postgresql.fullname" . }}-metrics"} / 3600 > 1
    ##     for: 1m
    ##     labels:
    ##       severity: critical
    ##     annotations:
    ##       description: replication for {{ template "postgresql.fullname" . }} PostgreSQL is lagging by {{ "{{ $value }}" }} hour(s).
    ##       summary: PostgreSQL replication is lagging by {{ "{{ $value }}" }} hour(s).
    ##
    rules: []
